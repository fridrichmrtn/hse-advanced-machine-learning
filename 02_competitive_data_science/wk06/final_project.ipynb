{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Martin Fridrich, 03/2022 \n",
    "\n",
    "# Final project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and initial transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from itertools import product\n",
    "import re\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/final_project/\"\n",
    "# sales\n",
    "sales_train = pd.read_csv(DATA_DIR+\"sales_train.csv\")\n",
    "sales_test = pd.read_csv(DATA_DIR+\"test.csv\")\n",
    "# addional info\n",
    "items = pd.read_csv(DATA_DIR+\"items.csv\")\n",
    "item_categories = pd.read_csv(DATA_DIR+\"item_categories.csv\")\n",
    "shops = pd.read_csv(DATA_DIR+\"shops.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downcast dataframe\n",
    "def optimize_numeric_dtypes(df):\n",
    "    float_cols = df.select_dtypes(\"float\").columns\n",
    "    int_cols = df.select_dtypes(\"integer\").columns\n",
    "    df.loc[:,float_cols] = df.loc[:, float_cols].\\\n",
    "        apply(pd.to_numeric, downcast=\"float\")\n",
    "    df.loc[:,int_cols] = df.loc[:, int_cols].\\\n",
    "        apply(pd.to_numeric, downcast=\"integer\")\n",
    "    return df\n",
    "\n",
    "def optimize_categories(df):\n",
    "    cat_cols = df.select_dtypes(\"object\").columns\n",
    "    df.loc[:,cat_cols] = df.loc[:,cat_cols].\\\n",
    "        apply(lambda x: x.astype(\"category\").cat.codes)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate shops\n",
    "shop_duplicates_map = {0: 57, 1: 58, 11: 10, 40: 39}\n",
    "sales_train[\"shop_id\"] = sales_train[\"shop_id\"].replace(shop_duplicates_map)\n",
    "# datetime\n",
    "sales_train[\"date\"] = pd.to_datetime(sales_train[\"date\"], format=\"%d.%m.%Y\")\n",
    "# remove first 2 months due to inconsistency\n",
    "sales_train = sales_train[sales_train.date_block_num>20]\n",
    "# filtering on test set\n",
    "sales_train = sales_train.loc[sales_train.shop_id.isin(sales_test[\"shop_id\"].unique()), :]\n",
    "# Drop training items with extreme or negative prices or sales counts\n",
    "sales_train = sales_train[((sales_train[\"item_price\"] > 0) & (sales_train[\"item_price\"] < 75000)) &\n",
    "    ((sales_train[\"item_cnt_day\"] > 0) & (sales_train[\"item_cnt_day\"] < 750))]\n",
    "# train cartesian product & inds\n",
    "shop_item_month = product(sales_train.shop_id.unique(), sales_train.item_id.unique(),\n",
    "    sales_train.date_block_num.unique())\n",
    "sales_train_index = pd.DataFrame(list(shop_item_month),\n",
    "    columns=[\"shop_id\",\"item_id\",\"date_block_num\"])\n",
    "# test inds\n",
    "sales_test_index = sales_test[[\"shop_id\",\"item_id\"]].copy()\n",
    "sales_test_index[\"date_block_num\"] = 34\n",
    "# inds\n",
    "sales_index = pd.concat([sales_train_index, sales_test_index],\n",
    "    ignore_index=True).reset_index(drop=True)\n",
    "del sales_test, sales_train_index, sales_test_index\n",
    "gc.collect()\n",
    "# sales table\n",
    "sales_train[\"revenue\"] = sales_train[\"item_price\"]*sales_train[\"item_cnt_day\"]\n",
    "sales = sales_train.groupby([\"shop_id\", \"item_id\", \"date_block_num\"], as_index=False).agg(\n",
    "    total_sold=(\"item_cnt_day\", sum),  sum_revenue=(\"revenue\",sum),\n",
    "    n_transactions = (\"item_cnt_day\",pd.Series.count))\\\n",
    "        .sort_values(\"date_block_num\")\n",
    "sales = sales_index.merge(sales, how=\"left\",\n",
    "    on=[\"shop_id\", \"item_id\", \"date_block_num\"]).fillna(0)\n",
    "sales = optimize_numeric_dtypes(sales)\n",
    "del sales_train, sales_index; gc.collect()\n",
    "sales.head(3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item groups based on adjacency and similarity\n",
    "items.item_name = items.item_name.apply(lambda x: re.sub(\"[^A-ZА-Яa-zа-я0-9 ]\",\"\", x))\n",
    "items.item_name = items.item_name.apply(lambda x: re.sub(\"\\\\s+\",\" \", x))\n",
    "item_names = pd.concat([items.item_id, items.item_name,\n",
    "    items.item_id.shift().fillna(0), items.item_name.shift().fillna(\"\")], axis=1)\n",
    "item_names.columns = [\"item_id\", \"item_name\", \"previous_item_id\", \"previous_item_name\"]\n",
    "item_names[\"similarity\"] = item_names.apply(\\\n",
    "     lambda x: fuzz.ratio(x[\"item_name\"],x[\"previous_item_name\"]), axis=1)\n",
    "item_names[\"group_start\"] = item_names[\"similarity\"] <= 75\n",
    "item_group_map = item_names.loc[item_names.group_start,[\"item_id\"]]\n",
    "item_group_map.columns = [\"group_start\"]\n",
    "item_group_map[\"group_end\"] = item_group_map[\"group_start\"].shift(-1).\\\n",
    "    fillna(item_group_map[\"group_start\"].max()+1).astype(\"int\")\n",
    "item_group_map[\"item_sim_id\"] = list(range(len(item_group_map)))\n",
    "# remap\n",
    "items = items.merge(item_group_map, how=\"left\",\n",
    "    left_on=[\"item_id\"], right_on=[\"group_start\"])\n",
    "items = items.sort_values(\"item_id\")\n",
    "items[\"item_sim_id\"] = items[\"item_sim_id\"].fillna(method=\"ffill\").astype(\"int\")\n",
    "del item_names, item_group_map; gc.collect()\n",
    "items = items[[\"item_id\",\"item_name\", \"item_category_id\", \"item_sim_id\"]]\n",
    "# name length\n",
    "items[\"item_name_len\"] = items.item_name.apply(len).astype(\"int16\")\n",
    "items.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories\n",
    "cat_splits = item_categories.item_category_name.apply(lambda x: x.split(\" - \"))\n",
    "item_categories = pd.concat([item_categories,\n",
    "    pd.DataFrame([c if len(c)>1 else [c[0],\"\"] for c in cat_splits],\n",
    "        columns=[\"parent_cat\",\"child_cat\"])], axis=1)\n",
    "items = items.merge(item_categories, how=\"inner\")\n",
    "# return categorical encoding\n",
    "items = optimize_categories(items[[\"item_id\", \"item_category_id\", \"item_sim_id\",\n",
    "    \"item_name_len\", \"parent_cat\", \"child_cat\"]])\n",
    "# add categories\n",
    "sales = sales.merge(items, how=\"inner\", on=\"item_id\")\n",
    "del item_categories, items; gc.collect()\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date features\n",
    "def working_days_count(from_date, to_date=None):\n",
    "    import pandas as pd\n",
    "    if to_date is None:\n",
    "        to_date=from_date+pd.DateOffset(months=1)\n",
    "    temp_date=from_date\n",
    "    cnt=0\n",
    "    while temp_date<to_date:\n",
    "        if temp_date.weekday()<5:\n",
    "            cnt+=1\n",
    "        temp_date+=pd.DateOffset(days=1)\n",
    "    return ((to_date-from_date).days, cnt, (to_date-from_date).days-cnt)\n",
    "dates = pd.DataFrame(sales.date_block_num.unique(), columns=[\"date_block_num\"])\n",
    "dates[\"date\"] = dates[\"date_block_num\"].apply(lambda x: pd.to_datetime(\"01/01/2013\")+\\\n",
    "    pd.DateOffset(months=x))\n",
    "dates[\"year\"] = dates.date.dt.year\n",
    "dates[\"month\"] = dates.date.dt.month\n",
    "dates = optimize_numeric_dtypes(pd.concat([dates, pd.DataFrame.from_records(\n",
    "        dates[\"date\"].apply(lambda x: working_days_count(x)),\n",
    "    columns=[\"total_days\", \"working_days\", \"weekend_days\"])], axis=1))\n",
    "sales = sales.merge(dates[[\"date_block_num\",\"year\",\"month\",\"total_days\", \"working_days\",\n",
    "    \"weekend_days\"]], how=\"inner\", on=\"date_block_num\")\n",
    "del dates; gc.collect()\n",
    "sales.head(3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricing overall and inside cat\n",
    "item_pricing = sales.groupby([\"date_block_num\",\"item_id\",\"item_category_id\"], as_index=False).\\\n",
    "    agg(total_sold=(\"total_sold\", sum),  sum_revenue=(\"sum_revenue\",sum))\n",
    "item_pricing.loc[:,\"average_price\"] = item_pricing[\"sum_revenue\"]/item_pricing[\"total_sold\"]\n",
    "item_pricing.loc[:,\"average_price\"]  = item_pricing.groupby([\"item_id\"])[\"average_price\"].\\\n",
    "    apply(lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\"))\n",
    "# add price changes\n",
    "item_pricing.loc[:,\"price_change\"] = item_pricing.groupby([\"item_id\"])[\"average_price\"].\\\n",
    "    apply(lambda x: x/x.shift()).fillna(1)\n",
    "# add position within the category\n",
    "item_pricing.loc[:,\"price_perc\"] = item_pricing.groupby([\"item_category_id\", \"date_block_num\"])\\\n",
    "    [\"average_price\"].apply(lambda x: x.rank(pct=True))\n",
    "item_pricing = optimize_numeric_dtypes(item_pricing[[\"date_block_num\", \"item_id\", \"price_change\",\n",
    "    \"price_perc\"]])\n",
    "sales = sales.merge(item_pricing, how=\"left\",\n",
    "    on=[\"date_block_num\", \"item_id\"])\n",
    "del item_pricing; gc.collect()\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shop location\n",
    "shops[\"city_id\"] = shops.shop_name.apply(lambda x:\\\n",
    "    re.sub(\"[^A-ZА-Яa-zа-я0-9 ]\",\"\", x.split(\" \")[0]))\n",
    "shops[\"city_code_id\"] = shops.shop_name.apply(lambda x:\\\n",
    "    re.sub(\"[^A-ZА-Яa-zа-я0-9 ]\",\"\", x.split(\" \")[1]))\n",
    "# keep wrong codes, so city and code are not the same\n",
    "# shops[\"city_code\"][shops.city==\"Якутск\"] = \"ТЦ\"\n",
    "shops = optimize_categories(shops[[\"shop_id\", \"city_id\", \"city_code_id\"]])\n",
    "sales = sales.merge(shops, how=\"inner\", on=\"shop_id\")\n",
    "del shops; gc.collect()\n",
    "sales.loc[:,\"target\"] = sales.groupby([\"item_id\",\"shop_id\"])[\"total_sold\"].\\\n",
    "    apply(lambda x: x.shift(-1)).fillna(0)\n",
    "sales.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time-series\n",
    "\n",
    "# smoothed demand across various cats\n",
    "# city\n",
    "sales[\"city_demand\"] = sales.groupby([\"city_id\",\"date_block_num\"])[\"total_sold\"].apply(lambda x:\n",
    "    x.ewm(span=3, min_periods=5).mean()).fillna(0).astype(\"float32\")\n",
    "# shop\n",
    "sales[\"shop_demand\"] = sales.groupby([\"shop_id\",\"date_block_num\"])[\"total_sold\"].apply(lambda x:\n",
    "    x.ewm(span=3, min_periods=5).mean()).fillna(0).astype(\"float32\")\n",
    "# category\n",
    "sales[\"cat_demand\"] = sales.groupby([\"item_category_id\",\"date_block_num\"])[\"total_sold\"].apply(lambda x:\n",
    "    x.ewm(span=3, min_periods=5).mean()).fillna(0).astype(\"float32\")\n",
    "# item\n",
    "sales[\"item_demand\"] = sales.groupby([\"item_id\",\"date_block_num\"])[\"total_sold\"].apply(lambda x:\n",
    "    x.ewm(span=3, min_periods=5).mean()).fillna(0).astype(\"float32\")\n",
    "sales = optimize_numeric_dtypes(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = [1,2,3,6]\n",
    "for l in lags:\n",
    "    sales.loc[:,\"lag\"+str(l)+\"_total_sold\"] = sales.groupby([sales.shop_id,sales.item_id])\\\n",
    "        [\"total_sold\"].shift(l).fillna(0)\n",
    "    sales.loc[:,\"lag\"+str(l)+\"_diff\"] = sales.loc[:,\"total_sold\"]-\\\n",
    "        sales.loc[:,\"lag\"+str(l)+\"_total_sold\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\"target\"]\n",
    "features = [c not in target for c in sales.columns]\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "last_block = 33\n",
    "train = sales[sales.date_block_num<last_block]\n",
    "test = sales[sales.date_block_num==last_block]\n",
    "gbm = RandomForestRegressor(n_jobs=4)\n",
    "gbm.fit(train.loc[:,features], train.loc[:,target])\n",
    "\n",
    "train_rsme = np.mean((gbm.predict(train.loc[:,features])-train.loc[:,\"target\"])**2)**(1/2)\n",
    "test_rsme = np.mean((gbm.predict(test.loc[:,features])-test.loc[:,\"target\"])**2)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "\n",
    "# mlp\n",
    "\n",
    "# random forest\n",
    "\n",
    "# lgbm\n",
    "\n",
    "# tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe955f705e5e305f9f1f02456b3a54982590d8b1fc3c3fbafb7ab752acef3d16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('py-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
